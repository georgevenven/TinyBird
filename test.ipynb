{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2b236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 21:36:06.798480: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-30 21:36:06.823513: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add ./src to Python path\n",
    "sys.path.append(str(Path().resolve() / \"src\"))\n",
    "\n",
    "# Now you can import modules\n",
    "from data_loader import SpectogramDataset\n",
    "from model import TinyBird\n",
    "from transformers import BertConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05481e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george-vengrovski/anaconda3/envs/tweetybert/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"patch_size\": (32, 8),           \n",
    "    \"max_seq\": 512,                   \n",
    "    \"enc_hidden_d\": 192,              # Encoder hidden dimension\n",
    "    \"dec_hidden_d\": 192,              # Decoder hidden dimension  \n",
    "    \"enc_n_head\": 4,                  # Encoder number of attention heads\n",
    "    \"enc_n_layer\": 3,                 # Encoder number of transformer layers\n",
    "    \"enc_dim_ff\": 768,                # Encoder feed-forward dimension\n",
    "    \"dec_n_head\": 4,                  # Decoder number of attention heads\n",
    "    \"dec_n_layer\": 3,                 # Decoder number of transformer layers\n",
    "    \"dec_dim_ff\": 768,                # Decoder feed-forward dimension\n",
    "    \"dropout\": 0.1,                   # Dropout rate\n",
    "    \"mask_p\": .25\n",
    "}\n",
    "\n",
    "tinybird = TinyBird(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b969d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing dataset statistics across 3451 files...\n",
      "Dataset statistics - Mean: -63.9062, Std: 16.9844\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataset = SpectogramDataset(dir=\"/media/george-vengrovski/disk1/llb3_train\", n_mels=128, n_timebins=1024)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "spec, label = next(iter(test_dataloader))\n",
    "\n",
    "# z = tinybird.project_to_patch(spec)\n",
    "# z = tinybird.encode_pos(z)\n",
    "\n",
    "# print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss = 0.810557, EMA Loss = 0.810557, LR = 1.00e-06\n",
      "Step 100: Loss = 0.524330, EMA Loss = 0.650493, LR = 1.10e-05\n",
      "Step 200: Loss = 0.467206, EMA Loss = 0.498355, LR = 2.10e-05\n",
      "Step 300: Loss = 0.444053, EMA Loss = 0.430169, LR = 3.09e-05\n",
      "Step 400: Loss = 0.312186, EMA Loss = 0.376660, LR = 4.09e-05\n",
      "Step 500: Loss = 0.285156, EMA Loss = 0.338288, LR = 5.09e-05\n",
      "Step 600: Loss = 0.299312, EMA Loss = 0.315272, LR = 6.09e-05\n",
      "Step 700: Loss = 0.298715, EMA Loss = 0.303633, LR = 7.09e-05\n",
      "Step 800: Loss = 0.288405, EMA Loss = 0.296296, LR = 8.08e-05\n",
      "Step 900: Loss = 0.241069, EMA Loss = 0.292467, LR = 9.08e-05\n",
      "Step 1000: Loss = 0.249323, EMA Loss = 0.287762, LR = 1.01e-04\n",
      "Step 1100: Loss = 0.296130, EMA Loss = 0.287744, LR = 1.11e-04\n",
      "Step 1200: Loss = 0.251789, EMA Loss = 0.284401, LR = 1.21e-04\n",
      "Step 1300: Loss = 0.234924, EMA Loss = 0.279878, LR = 1.31e-04\n",
      "Step 1400: Loss = 0.277207, EMA Loss = 0.278854, LR = 1.41e-04\n",
      "Step 1500: Loss = 0.308589, EMA Loss = 0.280710, LR = 1.51e-04\n",
      "Step 1600: Loss = 0.254769, EMA Loss = 0.279807, LR = 1.61e-04\n",
      "Step 1700: Loss = 0.278089, EMA Loss = 0.279246, LR = 1.71e-04\n",
      "Step 1800: Loss = 0.249969, EMA Loss = 0.275619, LR = 1.81e-04\n",
      "Step 1900: Loss = 0.272415, EMA Loss = 0.275826, LR = 1.91e-04\n",
      "Step 2000: Loss = 0.269343, EMA Loss = 0.276944, LR = 2.01e-04\n",
      "Step 2100: Loss = 0.258607, EMA Loss = 0.274061, LR = 2.11e-04\n",
      "Step 2200: Loss = 0.255942, EMA Loss = 0.273741, LR = 2.21e-04\n",
      "Step 2300: Loss = 0.275361, EMA Loss = 0.273497, LR = 2.31e-04\n",
      "Step 2400: Loss = 0.292203, EMA Loss = 0.271521, LR = 2.41e-04\n",
      "Step 2500: Loss = 0.281823, EMA Loss = 0.267430, LR = 2.51e-04\n",
      "Step 2600: Loss = 0.240257, EMA Loss = 0.267361, LR = 2.60e-04\n",
      "Step 2700: Loss = 0.269146, EMA Loss = 0.269597, LR = 2.70e-04\n",
      "Step 2800: Loss = 0.254494, EMA Loss = 0.267436, LR = 2.80e-04\n",
      "Step 2900: Loss = 0.245839, EMA Loss = 0.265464, LR = 2.90e-04\n",
      "Step 3000: Loss = 0.268390, EMA Loss = 0.268265, LR = 3.00e-04\n",
      "Step 3100: Loss = 0.260553, EMA Loss = 0.268736, LR = 3.10e-04\n",
      "Step 3200: Loss = 0.321686, EMA Loss = 0.269473, LR = 3.20e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m     42\u001b[0m         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lr\n\u001b[0;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m spec\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# (B,1,H,W)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m h, idx_restore, bool_mask, T \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward_encoder(x)\n\u001b[1;32m     48\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward_decoder(h, idx_restore, T)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# basic MAE-style training loop with recon dumps\n",
    "import os, torch, matplotlib.pyplot as plt\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = tinybird.to(device)\n",
    "opt = AdamW(model.parameters(), lr=1e-6, weight_decay=0.0)\n",
    "\n",
    "viz_every = 100\n",
    "max_steps = 20000\n",
    "warmup_steps = 5000\n",
    "target_lr = 5e-4\n",
    "patch_size = config[\"patch_size\"]\n",
    "H, W = test_dataset.n_mels, test_dataset.n_timebins\n",
    "\n",
    "def depatchify(pred: torch.Tensor) -> torch.Tensor:\n",
    "    # pred: (B, T, P) â†’ (B,1,H,W)\n",
    "    fold = nn.Fold(output_size=(H, W), kernel_size=patch_size, stride=patch_size)\n",
    "    return fold(pred.transpose(1, 2))\n",
    "\n",
    "def save_recon(x: torch.Tensor, pred: torch.Tensor, bool_mask: torch.Tensor, step: int, out_dir=\"recons\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Denormalize predictions to match original patch scale\n",
    "    def denormalize_predictions(x_patches, pred_patches):\n",
    "        # x_patches: (B, T, P), pred_patches: (B, T, P)\n",
    "        # Apply same normalization as loss function, then reverse it on predictions\n",
    "        target_mean = x_patches.mean(dim=-1, keepdim=True)\n",
    "        target_std = x_patches.std(dim=-1, keepdim=True)\n",
    "        # Denormalize: pred_denorm = pred * std + mean\n",
    "        pred_denorm = pred_patches * (target_std + 1e-6) + target_mean\n",
    "        return pred_denorm\n",
    "    \n",
    "    # Create overlay: unmasked original + masked predictions\n",
    "    def create_overlay(x_patches, pred_patches, bool_mask):\n",
    "        # x_patches: (B, T, P), pred_patches: (B, T, P), bool_mask: (B, T)\n",
    "        overlay_patches = x_patches.clone()\n",
    "        overlay_patches[bool_mask] = pred_patches[bool_mask]\n",
    "        return overlay_patches\n",
    "    \n",
    "    # Convert input to patches for overlay\n",
    "    unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "    x_patches = unfold(x).transpose(1, 2)  # (B, T, P)\n",
    "    \n",
    "    # Denormalize predictions to original scale\n",
    "    pred_denorm = denormalize_predictions(x_patches, pred)\n",
    "    \n",
    "    # Create overlay patches\n",
    "    overlay_patches = create_overlay(x_patches, pred_denorm, bool_mask)\n",
    "    \n",
    "    x_img = x[0, 0].detach().cpu().numpy()\n",
    "    r_img = depatchify(pred_denorm)[0, 0].detach().cpu().numpy()  # Use denormalized predictions\n",
    "    overlay_img = depatchify(overlay_patches)[0, 0].detach().cpu().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 4.5))  # taller figure for 3 rows\n",
    "    ax1 = plt.subplot(3, 1, 1); ax1.imshow(x_img, origin=\"lower\", aspect=\"auto\"); ax1.set_title(\"input\"); ax1.axis(\"off\")\n",
    "    ax2 = plt.subplot(3, 1, 2); ax2.imshow(r_img, origin=\"lower\", aspect=\"auto\"); ax2.set_title(\"recon\"); ax2.axis(\"off\")\n",
    "    ax3 = plt.subplot(3, 1, 3); ax3.imshow(overlay_img, origin=\"lower\", aspect=\"auto\"); ax3.set_title(\"overlay: unmasked original + masked predictions\"); ax3.axis(\"off\")\n",
    "    fig.tight_layout(); fig.savefig(f\"{out_dir}/step_{step:06d}.png\", dpi=150); plt.close(fig)\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "ema_loss = None\n",
    "ema_alpha = 0.99\n",
    "\n",
    "# Setup loss logging\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "loss_log_path = \"logs/loss_log.txt\"\n",
    "with open(loss_log_path, 'w') as f:\n",
    "    f.write(\"step,loss,ema_loss,lr\\n\")\n",
    "\n",
    "for epoch in range(2000):  # extend as needed\n",
    "    for spec, _ in test_dataloader:\n",
    "        # Learning rate schedule\n",
    "        if step < warmup_steps:\n",
    "            lr = 1e-6 + (target_lr - 1e-6) * (step / warmup_steps)\n",
    "            for param_group in opt.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        \n",
    "        x = spec.float().to(device, non_blocking=True)  # (B,1,H,W)\n",
    "        \n",
    "\n",
    "        h, idx_restore, bool_mask, T = model.forward_encoder(x)\n",
    "        pred = model.forward_decoder(h, idx_restore, T)\n",
    "        loss = model.loss_mse(x, pred, bool_mask)\n",
    "\n",
    "        # Update EMA loss\n",
    "        if ema_loss is None:\n",
    "            ema_loss = loss.item()\n",
    "        else:\n",
    "            ema_loss = ema_alpha * ema_loss + (1 - ema_alpha) * loss.item()\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if step % viz_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                h_v, idx_r_v, m_v, T_v = model.forward_encoder(x)\n",
    "                pred_v = model.forward_decoder(h_v, idx_r_v, T_v)\n",
    "                save_recon(x, pred_v, m_v, step)\n",
    "                current_lr = opt.param_groups[0]['lr']\n",
    "                print(f\"Step {step}: Loss = {loss.item():.6f}, EMA Loss = {ema_loss:.6f}, LR = {current_lr:.2e}\")\n",
    "                \n",
    "                # Log losses to file\n",
    "                with open(loss_log_path, 'a') as f:\n",
    "                    f.write(f\"{step},{loss.item():.6f},{ema_loss:.6f},{current_lr:.2e}\\n\")\n",
    "            model.train()\n",
    "\n",
    "        step += 1\n",
    "        if step >= max_steps:\n",
    "            break\n",
    "    if step >= max_steps:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetybert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
