#!/usr/bin/env python3
"""Analyze the impact of merging nearby chirps in audio2motif outputs."""
from __future__ import annotations

import argparse
import math
from pathlib import Path
from typing import Iterable, Iterator

import numpy as np
import torch


def parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Estimate how a chirp-merging policy would change chirp durations "
            "by scanning .pt files generated by audio2motif.py."
        )
    )
    parser.add_argument("--data_dir", type=Path, required=True, help="Directory containing .pt files.")
    parser.add_argument(
        "--gaps",
        type=int,
        nargs="+",
        default=[2, 5, 10, 20],
        help="Gap thresholds (in spectrogram columns) to test when merging adjacent chirps.",
    )
    parser.add_argument(
        "--max_files",
        type=int,
        default=None,
        help="Optional limit on number of .pt files to scan (handy for quick checks).",
    )
    return parser.parse_args(argv)


def _iter_pt_files(root: Path) -> Iterator[Path]:
    root = Path(root)
    if not root.exists():
        raise FileNotFoundError(f"data directory does not exist: {root}")
    for path in sorted(root.glob("**/*.pt")):
        if path.is_file():
            yield path


def _to_numpy(array) -> np.ndarray:
    if isinstance(array, torch.Tensor):
        return array.detach().cpu().numpy()
    return np.asarray(array)


def _channel_intervals(payload: dict, channel_index: int) -> np.ndarray:
    intervals_raw = payload.get("chirp_intervals")
    if intervals_raw is None:
        return np.empty((0, 2), dtype=np.int64)
    intervals = _to_numpy(intervals_raw)
    lengths = payload.get("chirp_lengths")
    length_arr = _to_numpy(lengths) if lengths is not None else None

    if intervals.ndim == 3:
        channel = intervals[channel_index]
        take = int(length_arr[channel_index]) if length_arr is not None else channel.shape[0]
        channel = channel[:take]
    else:
        channel = intervals

    channel = np.asarray(channel, dtype=np.int64).reshape(-1, 2)
    if channel.size == 0:
        return np.empty((0, 2), dtype=np.int64)
    valid = (channel[:, 0] >= 0) & (channel[:, 1] > channel[:, 0])
    channel = channel[valid]
    if channel.size == 0:
        return np.empty((0, 2), dtype=np.int64)
    order = np.argsort(channel[:, 0], kind="mergesort")
    return channel[order]


def _merge_intervals(intervals: np.ndarray, max_gap: int) -> np.ndarray:
    if intervals.size == 0:
        return intervals
    merged: list[list[int]] = []
    current = [int(intervals[0, 0]), int(intervals[0, 1])]
    for start, end in intervals[1:]:
        start = int(start)
        end = int(end)
        if start - current[1] <= max_gap:
            current[1] = max(current[1], end)
        else:
            merged.append(current)
            current = [start, end]
    merged.append(current)
    return np.asarray(merged, dtype=np.int64)


class RunningStats:
    __slots__ = ("count", "total", "total_sq", "min_val", "max_val")

    def __init__(self) -> None:
        self.count = 0
        self.total = 0.0
        self.total_sq = 0.0
        self.min_val = math.inf
        self.max_val = -math.inf

    def update(self, lengths: np.ndarray) -> None:
        if lengths.size == 0:
            return
        arr = np.asarray(lengths, dtype=np.float64).ravel()
        if arr.size == 0:
            return
        self.count += int(arr.size)
        self.total += float(np.sum(arr))
        self.total_sq += float(np.sum(arr * arr))
        self.min_val = min(self.min_val, float(np.min(arr)))
        self.max_val = max(self.max_val, float(np.max(arr)))

    def mean(self) -> float:
        if self.count == 0:
            return float("nan")
        return self.total / self.count

    def std(self) -> float:
        if self.count == 0:
            return float("nan")
        mean = self.mean()
        var = max(0.0, self.total_sq / self.count - mean * mean)
        return math.sqrt(var)


def analyze_directory(data_dir: Path, gaps: list[int], max_files: int | None = None) -> None:
    files_processed = 0
    channels_processed = 0
    stats = {gap: RunningStats() for gap in gaps}
    base_gap = 0

    for idx, pt_path in enumerate(_iter_pt_files(data_dir)):
        if max_files is not None and idx >= max_files:
            break
        payload = torch.load(pt_path, map_location="cpu")
        chirp_data = payload.get("chirp_intervals")
        if chirp_data is None:
            continue
        chirp_arr = _to_numpy(chirp_data)
        n_channels = chirp_arr.shape[0] if chirp_arr.ndim == 3 else 1
        for ch in range(n_channels):
            intervals = _channel_intervals(payload, ch)
            if intervals.size == 0:
                continue
            lengths = intervals[:, 1] - intervals[:, 0]
            stats[base_gap].update(lengths)
            for gap in gaps:
                if gap == 0:
                    continue
                merged = _merge_intervals(intervals, gap)
                merged_lengths = merged[:, 1] - merged[:, 0]
                stats[gap].update(merged_lengths)
            channels_processed += 1
        files_processed += 1

    baseline = stats[base_gap]
    if baseline.count == 0:
        print("No chirps found in the provided directory.")
        return

    print(
        f"Analyzed {files_processed} files, {channels_processed} channel streams. "
        f"Total chirps: {baseline.count} (mean length {baseline.mean():.2f} cols, std {baseline.std():.2f})."
    )
    header = (
        "gap_cols",
        "mean_len",
        "delta_vs_base",
        "std",
        "chirp_count",
        "count_delta",
    )
    print("\t".join(header))
    for gap in sorted(gaps):
        stats_gap = stats[gap]
        mean_len = stats_gap.mean()
        delta_mean = mean_len - baseline.mean()
        count_delta = stats_gap.count - baseline.count
        row = (
            str(gap),
            f"{mean_len:.2f}",
            f"{delta_mean:+.2f}",
            f"{stats_gap.std():.2f}",
            f"{stats_gap.count}",
            f"{count_delta:+d}",
        )
        print("\t".join(row))


def main(argv: Iterable[str] | None = None) -> None:
    args = parse_args(argv)
    unique_gaps = sorted(set(max(0, int(g)) for g in args.gaps))
    if 0 not in unique_gaps:
        unique_gaps.insert(0, 0)
    analyze_directory(args.data_dir, unique_gaps, max_files=args.max_files)


if __name__ == "__main__":
    main()
