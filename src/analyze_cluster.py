#!/usr/bin/env python3
"""Visualize clustering outputs generated by audio2cluster.py."""

from __future__ import annotations

import argparse
import os
import pickle
import sys
from pathlib import Path
from typing import Any, Iterable

import numpy as np

import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt  # noqa: E402
from matplotlib.patches import Patch  # noqa: E402


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Visualize per-channel clustering outputs produced by audio2cluster.py."
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--src_dir",
        type=str,
        help="Root directory containing input audio files (searched recursively).",
    )
    group.add_argument(
        "--file_list",
        type=str,
        help="Text file with absolute or relative paths to audio files, one per line.",
    )
    parser.add_argument(
        "--dst_dir",
        type=str,
        required=True,
        help="Destination directory used with audio2cluster.py (expects cluster/*.pkl).",
    )
    parser.add_argument("--sr", type=int, default=32_000, help="(unused placeholder for parity with audio2cluster)")
    parser.add_argument("--step_size", type=int, default=320, help="(unused placeholder for parity)")
    parser.add_argument("--nfft", type=int, default=1024, help="(unused placeholder for parity)")
    parser.add_argument("--n_mels", type=int, default=128, help="(unused placeholder for parity)")
    parser.add_argument("--min_len_ms", type=int, default=25, help="(unused placeholder for parity)")
    parser.add_argument("--min_timebins", type=int, default=25, help="(unused placeholder for parity)")
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Optional limit on number of files to visualize.",
    )
    parser.add_argument(
        "--max_blocks_per_cluster",
        type=int,
        default=16,
        help="Maximum number of block spectrograms to plot per cluster (default: 16).",
    )
    return parser.parse_args()


def gather_audio_files(args: argparse.Namespace) -> list[Path]:
    if args.file_list:
        file_list_path = Path(args.file_list)
        if not file_list_path.exists():
            print(f"[WARN] file list not found: {file_list_path}", file=sys.stderr)
            return []
        audio_exts = {".wav", ".mp3", ".ogg", ".flac"}
        suffix = file_list_path.suffix.lower()
        if suffix in audio_exts and file_list_path.exists():
            files = [file_list_path]
        else:
            try:
                text = file_list_path.read_text()
            except UnicodeDecodeError:
                if file_list_path.exists():
                    files = [file_list_path]
                else:
                    raise
            else:
                files = [Path(line.strip()) for line in text.splitlines() if line.strip()]
    elif args.src_dir:
        src_path = Path(args.src_dir)
        if not src_path.exists():
            print(f"[WARN] src_dir not found: {src_path}", file=sys.stderr)
            return []
        exts = (".wav", ".mp3", ".ogg", ".flac")
        files = [
            Path(root) / name
            for root, _, names in os.walk(src_path)
            for name in names
            if name.lower().endswith(exts)
        ]
    else:
        files = []

    if args.limit is not None and args.limit >= 0:
        files = files[: args.limit]
    return sorted(files)


def load_cluster_payload(path: Path) -> dict[str, Any]:
    with path.open("rb") as fh:
        return pickle.load(fh)


def ensure_output_dir(base_dir: Path, stem: str, channel_id: int) -> Path:
    out_dir = base_dir / stem / f"ch{channel_id}"
    out_dir.mkdir(parents=True, exist_ok=True)
    return out_dir


def build_color_map(cluster_ids: np.ndarray | Iterable[int]) -> dict[int, tuple[float, float, float, float]]:
    unique_ids = sorted(set(int(x) for x in np.asarray(cluster_ids).tolist()))
    cmap = plt.get_cmap("tab20", max(1, len(unique_ids)))
    return {cid: cmap(idx % cmap.N) for idx, cid in enumerate(unique_ids)}


def block_time(interval: tuple[int, int], frame_step: float) -> tuple[float, float]:
    start, end = interval
    start_time = max(0.0, start * frame_step)
    end_time = max(start_time, end * frame_step)
    return start_time, end_time


def create_overview_plot(
    payload: dict[str, Any],
    out_path: Path,
    stem: str,
    channel_id: int,
    frame_step: float,
) -> None:
    spectrogram = np.asarray(payload.get("S_db"))
    intervals = np.asarray(payload.get("chirp_intervals")).reshape(-1, 2)
    cluster_ids = np.asarray(payload.get("block_cluster_ids", []), dtype=int)

    if spectrogram.size == 0 or intervals.size == 0:
        return

    block_order = np.argsort(intervals[:, 0])
    sorted_intervals = intervals[block_order]
    sorted_clusters = cluster_ids[block_order] if cluster_ids.size else np.full(block_order.shape, -1, dtype=int)

    durations = (sorted_intervals[:, 1] - sorted_intervals[:, 0]) * frame_step
    if durations.size == 0:
        return

    max_time = np.max((sorted_intervals[:, 1]) * frame_step)
    colors = build_color_map(sorted_clusters if sorted_clusters.size else [0])

    fig_width = max(8.0, min(20.0, max_time / 5.0))
    fig_height = max(3.0, min(25.0, 0.35 * len(sorted_intervals) + 2.0))
    fig, (ax_stack, ax_spec, ax_blocks) = plt.subplots(
        3,
        1,
        figsize=(fig_width, fig_height + 4),
        gridspec_kw={"height_ratios": [len(sorted_intervals) * 0.35 + 1.0, 4, 1]},
        sharex=True,
    )

    legend_handles: list[Patch] = []
    for row, (interval, cluster_id) in enumerate(zip(sorted_intervals, sorted_clusters, strict=False)):
        start_time, end_time = block_time(tuple(map(int, interval)), frame_step)
        width = max(end_time - start_time, frame_step)
        color = colors.get(int(cluster_id), (0.7, 0.7, 0.7, 0.4))
        alpha = 0.65 if cluster_id >= 0 else 0.25
        ax_stack.barh(
            y=row,
            width=width,
            left=start_time,
            height=0.8,
            color=color,
            alpha=alpha,
            edgecolor="black",
            linewidth=0.6,
        )
        ax_stack.text(
            start_time + width / 2.0,
            row,
            f"{cluster_id}",
            ha="center",
            va="center",
            fontsize=8,
            color="white",
            bbox=dict(facecolor=color, alpha=0.8, boxstyle="round,pad=0.2"),
        )
        label_text = f"cluster {cluster_id}" if cluster_id >= 0 else "noise"
        handle = Patch(facecolor=color, alpha=alpha, label=label_text, edgecolor="black")
        if not any(h.get_label() == handle.get_label() for h in legend_handles):
            legend_handles.append(handle)

    ax_stack.set_xlim(0.0, max_time if max_time > 0 else 1.0)
    ax_stack.set_ylim(-0.5, len(sorted_intervals) - 0.5)
    ax_stack.set_ylabel("Blocks (sorted)")
    ax_stack.set_title(f"{stem} | channel {channel_id} | block overview")
    ax_stack.set_yticks([])

    if legend_handles:
        ax_stack.legend(handles=legend_handles, loc="upper right", fontsize=8)

    time_extent = [0.0, max_time, 0, spectrogram.shape[0]]

    im = ax_spec.imshow(
        spectrogram,
        aspect="auto",
        origin="lower",
        cmap="magma",
        extent=time_extent,
    )
    ax_spec.set_ylabel("Mel bin")
    ax_spec.set_title(f"{stem} | channel {channel_id} | spectrogram (blocks only)")
    fig.colorbar(im, ax=ax_spec, orientation="vertical", fraction=0.035, pad=0.01, label="dB")

    legend_handles: list[Patch] = []
    if cluster_ids.size == 0:
        cluster_ids = np.full(intervals.shape[0], -1, dtype=int)

    for block_idx, (interval, cluster_id) in enumerate(zip(intervals, cluster_ids, strict=False)):
        start_time, end_time = block_time(tuple(map(int, interval)), frame_step)
        color = colors.get(int(cluster_id), (0.7, 0.7, 0.7, 0.4))
        alpha = 0.35 if cluster_id >= 0 else 0.15
        ax_spec.axvspan(start_time, end_time, color=color, alpha=alpha)
        mid_time = (start_time + end_time) * 0.5
        if end_time > start_time:
            ax_spec.text(
                mid_time,
                spectrogram.shape[0] * 0.95,
                f"{cluster_id}",
                ha="center",
                va="top",
                fontsize=8,
                color="white",
                bbox=dict(facecolor=color, alpha=0.6, boxstyle="round,pad=0.2"),
            )
        label_text = f"cluster {cluster_id}" if cluster_id >= 0 else "noise"
        handle = Patch(facecolor=color, alpha=0.6, label=label_text)
        if not any(h.get_label() == handle.get_label() for h in legend_handles):
            legend_handles.append(handle)

        ax_blocks.barh(
            y=0.5,
            width=end_time - start_time,
            left=start_time,
            color=color,
            alpha=alpha,
            edgecolor="black",
        )

    ax_blocks.set_xlim(0, max(max_time, 1e-6))
    ax_blocks.set_xlabel("Time (s)")
    ax_blocks.set_yticks([])
    ax_blocks.set_title("Block assignments")
    if legend_handles:
        ax_blocks.legend(
            handles=legend_handles,
            loc="upper center",
            ncol=min(4, len(legend_handles)),
            bbox_to_anchor=(0.5, 1.45),
            fontsize=8,
        )

    ax_spec.set_xlim(0, max(max_time, 1e-6))
    ax_blocks.set_xlim(0, max(max_time, 1e-6))
    ax_blocks.set_xlabel("Time (s)")
    ax_blocks.set_yticks([])
    ax_blocks.set_title("Block assignments")
    ax_spec.set_xticks(np.linspace(0, max_time, num=6))

    ax_blocks.set_position([ax_blocks.get_position().x0, ax_blocks.get_position().y0, ax_blocks.get_position().width, ax_blocks.get_position().height])

    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


def compute_cluster_blocks(
    payload: dict[str, Any],
) -> dict[int, list[tuple[int, int, np.ndarray]]]:
    spectrogram = np.asarray(payload.get("S_db"))
    intervals = np.asarray(payload.get("chirp_intervals")).reshape(-1, 2)
    cluster_ids = np.asarray(payload.get("block_cluster_ids", []), dtype=int)

    clusters: dict[int, list[tuple[int, int, np.ndarray]]] = {}
    for idx, (interval, cluster_id) in enumerate(zip(intervals, cluster_ids, strict=False)):
        start = int(interval[0])
        end = int(interval[1])
        snippet = spectrogram[:, start:end] if spectrogram.size else np.empty((0, 0))
        clusters.setdefault(int(cluster_id), []).append((start, end, snippet))
    return clusters


def plot_cluster_snippets(
    payload: dict[str, Any],
    clusters: dict[int, list[tuple[int, int, np.ndarray]]],
    out_dir: Path,
    channel_id: int,
    frame_step: float,
    max_blocks_per_cluster: int,
) -> None:
    for cluster_id, blocks in sorted(clusters.items(), key=lambda item: item[0]):
        label = "noise" if cluster_id < 0 else f"cluster {cluster_id}"
        trimmed_blocks = blocks[:max_blocks_per_cluster]

        if not trimmed_blocks:
            continue

        n_blocks = len(trimmed_blocks)
        durations = [max((end - start) * frame_step, frame_step) for (start, end, _snippet) in trimmed_blocks]
        max_duration = max(durations)

        fig_width = max(6.0, min(18.0, max_duration * 2.0))
        fig_height = max(2.5, min(20.0, n_blocks * 2.0))

        fig, axes = plt.subplots(
            n_blocks,
            1,
            figsize=(fig_width, fig_height),
            sharex=True,
            squeeze=False,
        )

        for ax_idx, (block, duration) in enumerate(zip(trimmed_blocks, durations, strict=False)):
            start, end, snippet = block
            ax = axes[ax_idx][0]
            ax.set_facecolor("white")
            if snippet.size == 0:
                ax.text(0.5, 0.5, "(empty)", transform=ax.transAxes, ha="center", va="center")
            else:
                extent = [0.0, duration, 0, snippet.shape[0]]
                ax.imshow(
                    snippet,
                    aspect="auto",
                    origin="lower",
                    cmap="magma",
                    extent=extent,
                )
            ax.set_ylabel("Mel")
            ax.set_title(f"Frames {start}-{end}", fontsize=9, loc="left")
            ax.set_xlim(0.0, max_duration)
            ax.tick_params(axis="y", labelleft=False)
            ax.tick_params(axis="x", labelbottom=ax_idx == n_blocks - 1)

        axes[-1][0].set_xlabel("Time (s)")

        fig.suptitle(f"Channel {channel_id} | {label} | {n_blocks} block(s)", fontsize=14)
        fig.tight_layout(rect=[0, 0, 1, 0.97])
        out_path = out_dir / f"cluster_{cluster_id if cluster_id >= 0 else 'noise'}.png"
        fig.savefig(out_path, dpi=200)
        plt.close(fig)


def process_channel_file(
    pkl_path: Path,
    analysis_root: Path,
    stem: str,
    max_blocks_per_cluster: int,
) -> None:
    payload = load_cluster_payload(pkl_path)
    channel_id = infer_channel_id(pkl_path)
    out_dir = ensure_output_dir(analysis_root, stem, channel_id)

    overview_path = out_dir / "overview.png"
    meta = payload.get("meta", {})
    sr = meta.get("sr") or 0
    hop_length = meta.get("hop_length") or 0
    frame_step = (hop_length / sr) if (sr and hop_length) else 1.0
    create_overview_plot(payload, overview_path, stem, channel_id, frame_step)

    clusters = compute_cluster_blocks(payload)
    plot_cluster_snippets(payload, clusters, out_dir, channel_id, frame_step, max_blocks_per_cluster)


def infer_channel_id(path: Path) -> int:
    name = path.stem
    if "_ch" in name:
        try:
            return int(name.split("_ch")[-1])
        except ValueError:
            return 0
    return 0


def main() -> None:
    args = parse_args()
    cluster_dir = Path(args.dst_dir) / "cluster"
    if not cluster_dir.exists():
        print(f"[ERROR] cluster directory not found: {cluster_dir}", file=sys.stderr)
        sys.exit(1)

    analysis_dir = cluster_dir / "analysis"
    analysis_dir.mkdir(parents=True, exist_ok=True)

    audio_files = gather_audio_files(args)
    if not audio_files:
        print("[WARN] no audio files detected; nothing to visualize.", file=sys.stderr)
        return

    processed = 0
    for audio_path in audio_files:
        stem = audio_path.stem
        channel_pickles = sorted(cluster_dir.glob(f"{stem}_ch*.pkl"))
        if not channel_pickles:
            print(f"[WARN] no cluster files found for {stem}", file=sys.stderr)
            continue

        for pkl_path in channel_pickles:
            try:
                process_channel_file(
                    pkl_path=pkl_path,
                    analysis_root=analysis_dir,
                    stem=stem,
                    max_blocks_per_cluster=args.max_blocks_per_cluster,
                )
                processed += 1
            except Exception as exc:  # pragma: no cover - visualization best effort
                print(f"[ERROR] failed to process {pkl_path}: {exc}", file=sys.stderr)

    print(f"Generated visualizations for {processed} channel(s). Output: {analysis_dir}")


if __name__ == "__main__":
    main()
