#!/usr/bin/env python3
"""Visualize clustering outputs generated by audio2cluster.py."""

from __future__ import annotations

import argparse
import math
import os
import pickle
import sys
from pathlib import Path
from typing import Any, Iterable

import numpy as np

import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt  # noqa: E402
from matplotlib.patches import Patch  # noqa: E402


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Visualize per-channel clustering outputs produced by audio2cluster.py."
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--src_dir",
        type=str,
        help="Root directory containing input audio files (searched recursively).",
    )
    group.add_argument(
        "--file_list",
        type=str,
        help="Text file with absolute or relative paths to audio files, one per line.",
    )
    parser.add_argument(
        "--dst_dir",
        type=str,
        required=True,
        help="Destination directory used with audio2cluster.py (expects cluster/*.pkl).",
    )
    parser.add_argument("--sr", type=int, default=32_000, help="(unused placeholder for parity with audio2cluster)")
    parser.add_argument("--step_size", type=int, default=320, help="(unused placeholder for parity)")
    parser.add_argument("--nfft", type=int, default=1024, help="(unused placeholder for parity)")
    parser.add_argument("--n_mels", type=int, default=128, help="(unused placeholder for parity)")
    parser.add_argument("--min_len_ms", type=int, default=25, help="(unused placeholder for parity)")
    parser.add_argument("--min_timebins", type=int, default=25, help="(unused placeholder for parity)")
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Optional limit on number of files to visualize.",
    )
    parser.add_argument(
        "--max_blocks_per_cluster",
        type=int,
        default=16,
        help="Maximum number of block spectrograms to plot per cluster (default: 16).",
    )
    return parser.parse_args()


def gather_audio_files(args: argparse.Namespace) -> list[Path]:
    if args.file_list:
        file_list_path = Path(args.file_list)
        if not file_list_path.exists():
            print(f"[WARN] file list not found: {file_list_path}", file=sys.stderr)
            return []
        files = [
            Path(line.strip())
            for line in file_list_path.read_text().splitlines()
            if line.strip()
        ]
    elif args.src_dir:
        src_path = Path(args.src_dir)
        if not src_path.exists():
            print(f"[WARN] src_dir not found: {src_path}", file=sys.stderr)
            return []
        exts = (".wav", ".mp3", ".ogg", ".flac")
        files = [
            Path(root) / name
            for root, _, names in os.walk(src_path)
            for name in names
            if name.lower().endswith(exts)
        ]
    else:
        files = []

    if args.limit is not None and args.limit >= 0:
        files = files[: args.limit]
    return sorted(files)


def load_cluster_payload(path: Path) -> dict[str, Any]:
    with path.open("rb") as fh:
        return pickle.load(fh)


def ensure_output_dir(base_dir: Path, stem: str, channel_id: int) -> Path:
    out_dir = base_dir / stem / f"ch{channel_id}"
    out_dir.mkdir(parents=True, exist_ok=True)
    return out_dir


def build_color_map(cluster_ids: np.ndarray | Iterable[int]) -> dict[int, tuple[float, float, float, float]]:
    unique_ids = sorted(set(int(x) for x in np.asarray(cluster_ids).tolist()))
    cmap = plt.get_cmap("tab20", max(1, len(unique_ids)))
    return {cid: cmap(idx % cmap.N) for idx, cid in enumerate(unique_ids)}


def block_time(interval: tuple[int, int], frame_step: float) -> tuple[float, float]:
    start, end = interval
    start_time = max(0.0, start * frame_step)
    end_time = max(start_time, end * frame_step)
    return start_time, end_time


def create_overview_plot(
    payload: dict[str, Any],
    out_path: Path,
    stem: str,
    channel_id: int,
) -> None:
    spectrogram = np.asarray(payload.get("S_db"))
    intervals = np.asarray(payload.get("chirp_intervals")).reshape(-1, 2)
    cluster_ids = np.asarray(payload.get("block_cluster_ids", []), dtype=int)

    meta = payload.get("meta", {})
    sr = meta.get("sr") or 0
    hop_length = meta.get("hop_length") or 0
    frame_step = (hop_length / sr) if (sr and hop_length) else 1.0

    if spectrogram.size == 0 or intervals.size == 0:
        return

    n_frames = spectrogram.shape[1]
    total_duration = n_frames * frame_step

    colors = build_color_map(cluster_ids if cluster_ids.size else [0])
    time_extent = [0.0, total_duration, 0, spectrogram.shape[0]]

    fig, (ax_spec, ax_blocks) = plt.subplots(
        2,
        1,
        figsize=(14, 8),
        sharex=True,
        gridspec_kw={"height_ratios": [4, 1]},
    )

    im = ax_spec.imshow(
        spectrogram,
        aspect="auto",
        origin="lower",
        cmap="magma",
        extent=time_extent,
    )
    ax_spec.set_ylabel("Mel bin")
    ax_spec.set_title(f"{stem} | channel {channel_id} | full spectrogram")
    fig.colorbar(im, ax=ax_spec, orientation="vertical", fraction=0.045, pad=0.01, label="dB")

    legend_handles: list[Patch] = []
    if cluster_ids.size == 0:
        cluster_ids = np.full(intervals.shape[0], -1, dtype=int)

    for block_idx, (interval, cluster_id) in enumerate(zip(intervals, cluster_ids, strict=False)):
        start_time, end_time = block_time(tuple(map(int, interval)), frame_step)
        color = colors.get(int(cluster_id), (0.7, 0.7, 0.7, 0.4))
        alpha = 0.35 if cluster_id >= 0 else 0.15
        ax_spec.axvspan(start_time, end_time, color=color, alpha=alpha)
        mid_time = (start_time + end_time) * 0.5
        if end_time > start_time:
            ax_spec.text(
                mid_time,
                spectrogram.shape[0] * 0.95,
                f"{cluster_id}",
                ha="center",
                va="top",
                fontsize=8,
                color="white",
                bbox=dict(facecolor=color, alpha=0.6, boxstyle="round,pad=0.2"),
            )
        label_text = f"cluster {cluster_id}" if cluster_id >= 0 else "noise"
        handle = Patch(color=color, alpha=0.6, label=label_text)
        if not any(h.get_label() == handle.get_label() for h in legend_handles):
            legend_handles.append(handle)

        ax_blocks.barh(
            y=0.5,
            width=end_time - start_time,
            left=start_time,
            color=color,
            alpha=alpha,
            edgecolor="black",
        )

    ax_blocks.set_xlim(0, max(total_duration, 1e-6))
    ax_blocks.set_xlabel("Time (s)")
    ax_blocks.set_yticks([])
    ax_blocks.set_title("Block assignments")
    if legend_handles:
        ax_blocks.legend(
            handles=legend_handles,
            loc="upper center",
            ncol=min(4, len(legend_handles)),
            bbox_to_anchor=(0.5, 1.45),
            fontsize=8,
        )

    ax_spec.set_xlim(0, max(total_duration, 1e-6))
    ax_spec.set_xticks(np.linspace(0, total_duration, num=6))

    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)


def compute_cluster_blocks(
    payload: dict[str, Any],
) -> dict[int, list[tuple[int, int, np.ndarray]]]:
    spectrogram = np.asarray(payload.get("S_db"))
    intervals = np.asarray(payload.get("chirp_intervals")).reshape(-1, 2)
    cluster_ids = np.asarray(payload.get("block_cluster_ids", []), dtype=int)

    clusters: dict[int, list[tuple[int, int, np.ndarray]]] = {}
    for idx, (interval, cluster_id) in enumerate(zip(intervals, cluster_ids, strict=False)):
        start = int(interval[0])
        end = int(interval[1])
        snippet = spectrogram[:, start:end] if spectrogram.size else np.empty((0, 0))
        clusters.setdefault(int(cluster_id), []).append((start, end, snippet))
    return clusters


def plot_cluster_snippets(
    payload: dict[str, Any],
    clusters: dict[int, list[tuple[int, int, np.ndarray]]],
    out_dir: Path,
    channel_id: int,
    frame_step: float,
    max_blocks_per_cluster: int,
) -> None:
    for cluster_id, blocks in sorted(clusters.items(), key=lambda item: item[0]):
        label = "noise" if cluster_id < 0 else f"cluster {cluster_id}"
        trimmed_blocks = blocks[:max_blocks_per_cluster]

        if not trimmed_blocks:
            continue

        n_blocks = len(trimmed_blocks)
        cols = min(4, n_blocks)
        rows = math.ceil(n_blocks / cols)

        fig, axes = plt.subplots(
            rows,
            cols,
            figsize=(cols * 4, rows * 3),
            squeeze=False,
        )

        for ax in axes.flat:
            ax.axis("off")

        for idx, (block) in enumerate(trimmed_blocks):
            start, end, snippet = block
            row = idx // cols
            col = idx % cols
            ax = axes[row][col]
            ax.axis("on")
            if snippet.size == 0:
                ax.set_title(f"Block {idx} (empty)")
                continue
            duration = max((end - start) * frame_step, frame_step)
            extent = [0.0, duration, 0, snippet.shape[0]]
            ax.imshow(
                snippet,
                aspect="auto",
                origin="lower",
                cmap="magma",
                extent=extent,
            )
            ax.set_title(f"Frames {start}-{end}", fontsize=9)
            ax.set_xlabel("Time (s)")
            ax.set_ylabel("Mel bin")

        fig.suptitle(f"Channel {channel_id} | {label} | {n_blocks} block(s)", fontsize=14)
        fig.tight_layout(rect=[0, 0, 1, 0.97])
        out_path = out_dir / f"cluster_{cluster_id if cluster_id >= 0 else 'noise'}.png"
        fig.savefig(out_path, dpi=200)
        plt.close(fig)


def process_channel_file(
    pkl_path: Path,
    analysis_root: Path,
    stem: str,
    max_blocks_per_cluster: int,
) -> None:
    payload = load_cluster_payload(pkl_path)
    channel_id = infer_channel_id(pkl_path)
    out_dir = ensure_output_dir(analysis_root, stem, channel_id)

    overview_path = out_dir / "overview.png"
    meta = payload.get("meta", {})
    sr = meta.get("sr") or 0
    hop_length = meta.get("hop_length") or 0
    frame_step = (hop_length / sr) if (sr and hop_length) else 1.0
    create_overview_plot(payload, overview_path, stem, channel_id)

    clusters = compute_cluster_blocks(payload)
    plot_cluster_snippets(payload, clusters, out_dir, channel_id, frame_step, max_blocks_per_cluster)


def infer_channel_id(path: Path) -> int:
    name = path.stem
    if "_ch" in name:
        try:
            return int(name.split("_ch")[-1])
        except ValueError:
            return 0
    return 0


def main() -> None:
    args = parse_args()
    cluster_dir = Path(args.dst_dir) / "cluster"
    if not cluster_dir.exists():
        print(f"[ERROR] cluster directory not found: {cluster_dir}", file=sys.stderr)
        sys.exit(1)

    analysis_dir = cluster_dir / "analysis"
    analysis_dir.mkdir(parents=True, exist_ok=True)

    audio_files = gather_audio_files(args)
    if not audio_files:
        print("[WARN] no audio files detected; nothing to visualize.", file=sys.stderr)
        return

    processed = 0
    for audio_path in audio_files:
        stem = audio_path.stem
        channel_pickles = sorted(cluster_dir.glob(f"{stem}_ch*.pkl"))
        if not channel_pickles:
            print(f"[WARN] no cluster files found for {stem}", file=sys.stderr)
            continue

        for pkl_path in channel_pickles:
            try:
                process_channel_file(
                    pkl_path=pkl_path,
                    analysis_root=analysis_dir,
                    stem=stem,
                    max_blocks_per_cluster=args.max_blocks_per_cluster,
                )
                processed += 1
            except Exception as exc:  # pragma: no cover - visualization best effort
                print(f"[ERROR] failed to process {pkl_path}: {exc}", file=sys.stderr)

    print(f"Generated visualizations for {processed} channel(s). Output: {analysis_dir}")


if __name__ == "__main__":
    main()
